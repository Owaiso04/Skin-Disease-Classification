{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa91d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras import layers, models\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da449b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(image_paths, labels, img_size=(224, 224)):\n",
    "    X, y = [], []\n",
    "    for p, label in zip(image_paths, labels):\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = preprocess_input(img.astype(\"float32\"))\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43299b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Load metadata and split ───────────────────────────────────────────────────\n",
    "metadata = pd.read_csv(\"./HAM10000/HAM10000_metadata.csv\")\n",
    "image_dir_1 = \"./HAM10000/HAM10000_images_part_1/\"\n",
    "image_dir_2 = \"./HAM10000/HAM10000_images_part_2/\"\n",
    "\n",
    "\n",
    "def get_image_path(image_id):\n",
    "    path = os.path.join(image_dir_1, image_id + \".jpg\")\n",
    "    if not os.path.exists(path):\n",
    "        path = os.path.join(image_dir_2, image_id + \".jpg\")\n",
    "    return path\n",
    "\n",
    "\n",
    "df = metadata[metadata[\"dx\"].isin([\"nv\", \"mel\"])].copy()\n",
    "df[\"label\"] = df[\"dx\"].map({\"nv\": 0, \"mel\": 1})\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(get_image_path)\n",
    "\n",
    "# Undersampling nv Class\n",
    "mel_df = df[df[\"label\"] == 1]\n",
    "nv_df = df[df[\"label\"] == 0].sample(n=len(mel_df), random_state=42)\n",
    "\n",
    "df = pd.concat([mel_df, nv_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "X_train, y_train = load_and_preprocess(\n",
    "    train_df[\"image_path\"].tolist(), train_df[\"label\"].tolist()\n",
    ")\n",
    "X_test, y_test = load_and_preprocess(\n",
    "    test_df[\"image_path\"].tolist(), test_df[\"label\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82070e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# os.makedirs(\"test_images/mel\", exist_ok=True)\n",
    "# os.makedirs(\"test_images/nv\", exist_ok=True)\n",
    "\n",
    "# for _, row in test_df.iterrows():\n",
    "#     dest_dir = \"test_images/mel\" if row[\"label\"] == 1 else \"test_images/nv\"\n",
    "#     shutil.copy(\n",
    "#         row[\"image_path\"], os.path.join(dest_dir, os.path.basename(row[\"image_path\"]))\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb387db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Balance via two ImageDataGenerator flows ─────────────────────────────────\n",
    "batch_size = 32\n",
    "half_bs = batch_size // 2\n",
    "\n",
    "# split by class\n",
    "y_train = y_train.flatten()\n",
    "X_train_nv = X_train[y_train == 0]\n",
    "y_train_nv = y_train[y_train == 0]\n",
    "X_train_mel = X_train[y_train == 1]\n",
    "y_train_mel = y_train[y_train == 1]\n",
    "\n",
    "aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "gen_nv = aug.flow(X_train_nv, y_train_nv, batch_size=half_bs, shuffle=True)\n",
    "gen_mel = aug.flow(X_train_mel, y_train_mel, batch_size=half_bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c8ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Custom Sequence to interleave nv/mel ────────────────────────────────────\n",
    "class BalancedSequence(keras.utils.Sequence):\n",
    "    def __init__(self, gen0, gen1):\n",
    "        self.gen0 = gen0\n",
    "        self.gen1 = gen1\n",
    "        # length = how many batches we can draw evenly\n",
    "        self._len = min(len(gen0), len(gen1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X0, y0 = self.gen0[idx]\n",
    "        X1, y1 = self.gen1[idx]\n",
    "        Xb = np.vstack([X0, X1])\n",
    "        yb = np.concatenate([y0, y1])\n",
    "        perm = np.random.permutation(len(yb))\n",
    "        return Xb[perm], yb[perm]\n",
    "\n",
    "\n",
    "train_seq = BalancedSequence(gen_nv, gen_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eaede6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss\n",
    "import tensorflow.keras.backend as k\n",
    "\n",
    "\n",
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = k.epsilon()\n",
    "        y_pred = k.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        pt_1 = tf.where(k.equal(y_true, 1), y_pred, k.ones_like(y_pred))\n",
    "        pt_0 = tf.where(k.equal(y_true, 0), y_pred, k.zeros_like(y_pred))\n",
    "        return -k.mean(alpha * k.pow(1.0 - pt_1, gamma) * k.log(pt_1)) - k.mean(\n",
    "            (1 - alpha) * k.pow(pt_0, gamma) * k.log(1.0 - pt_0)\n",
    "        )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3afb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Build & compile model ───────────────────────────────────────────────────\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = ResNet50(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\"\n",
    ")\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", classes=np.unique(y_train), y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=binary_focal_loss(gamma=2.0, alpha=0.25),\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc36a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6647 - auc: 0.7804 - loss: 0.1253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.6651 - auc: 0.7812 - loss: 0.1245 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 1.9831\n",
      "Epoch 2/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7506 - auc: 0.8978 - loss: 0.0438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.7510 - auc: 0.8981 - loss: 0.0438 - val_accuracy: 0.7735 - val_auc: 0.8706 - val_loss: 0.1242\n",
      "Epoch 3/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8059 - auc: 0.9405 - loss: 0.0342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.8059 - auc: 0.9404 - loss: 0.0343 - val_accuracy: 0.8453 - val_auc: 0.9294 - val_loss: 0.0686\n",
      "Epoch 4/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8263 - auc: 0.9473 - loss: 0.0327 - val_accuracy: 0.8341 - val_auc: 0.9225 - val_loss: 0.0758\n",
      "Epoch 5/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.8571 - auc: 0.9615 - loss: 0.0281 - val_accuracy: 0.8565 - val_auc: 0.9309 - val_loss: 0.0703\n",
      "Epoch 6/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.8563 - auc: 0.9666 - loss: 0.0267 - val_accuracy: 0.8453 - val_auc: 0.9305 - val_loss: 0.0824\n"
     ]
    }
   ],
   "source": [
    "# ─── Training ────────────────────────────────────────────────────────────────\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"resnet_model_nv_mel_ES.h5\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_seq,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test[:500], y_test[:500]),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4e3865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"resnet_model_nv_mel_ES.h5\",\n",
    "    custom_objects={\"loss\": binary_focal_loss(gamma=2.0, alpha=0.25)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b67b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "val_probs = model.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd1580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal sigmoid threshold = 0.482\n"
     ]
    }
   ],
   "source": [
    "# Threshold Tuning\n",
    "fpr, tpr, thresholds = roc_curve(y_test, val_probs)\n",
    "youden_j = tpr - fpr\n",
    "best_idx = np.argmax(youden_j)\n",
    "best_thresh = thresholds[best_idx]\n",
    "print(f\"Optimal sigmoid threshold = {best_thresh:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b03b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate\n",
    "test_loss, test_acc, test_auc = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d98860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = (val_probs >= best_thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e777a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0686, Test Accuracy: 0.8453, Test AUC: 0.9294\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}, Test AUC: {test_auc:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e14fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          nv       0.92      0.78      0.84       223\n",
      "         mel       0.81      0.93      0.86       223\n",
      "\n",
      "    accuracy                           0.85       446\n",
      "   macro avg       0.86      0.85      0.85       446\n",
      "weighted avg       0.86      0.85      0.85       446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, test_preds, target_names=[\"nv\", \"mel\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            nv (pred)  mel (pred)\n",
      "nv (true)         173          50\n",
      "mel (true)         16         207\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_preds, labels=[0, 1])\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"nv (true)\", \"mel (true)\"], columns=[\"nv (pred)\", \"mel (pred)\"]\n",
    ")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfd15cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8520\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, test_preds):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
